import subprocess
import sys

# --- è‡ªå‹•ç’°å¢ƒæª¢æŸ¥æ©Ÿåˆ¶ ---
def setup_environment():
    required = {"numpy", "pandas", "matplotlib", "scipy", "requests", "emcee", "corner"}
    try:
        import pkg_resources
        installed = {pkg.key for pkg in pkg_resources.working_set}
        missing = required - installed
        if missing:
            print(f"[*] åµæ¸¬åˆ°ç¼ºå¤±çµ„ä»¶: {missing}ï¼Œæ­£åœ¨è‡ªå‹•å®‰è£...")
            subprocess.check_call([sys.executable, "-m", "pip", "install", *missing])
    except Exception:
        # é‡å° Colab ç’°å¢ƒçš„ç›¸å®¹è™•ç†
        pass

setup_environment()

# --- æ­£å¼å°å…¥ ---

import numpy as np
import pandas as pd
import emcee
import matplotlib.pyplot as plt
import corner
import requests
import io
import sys

# --- 1. çœŸå¯¦æ•¸æ“šç²å–å¼•æ“ (ä¸å†æœ‰æ¨¡æ“¬å‚™æ´) ---

def get_real_pantheon_data():
    print("[*] æ­£åœ¨å˜—è©¦å¾å¤šå€‹å­¸è¡“é¡åƒç«™ç²å–çœŸå¯¦ Pantheon+ æ•¸æ“š...")
    
    # é€™è£¡ä½¿ç”¨ä¸‰å€‹ä¸åŒçš„å®˜æ–¹/å­¸è¡“é¡åƒåœ°å€
    urls = [
        # 1. åŸå§‹ GitHub Raw (å˜—è©¦è½‰ç¾©)
        "https://raw.githubusercontent.com/PantheonPlusSH0ES/DataRelease/main/Pantheon%2B_Data/4_SHOES/Pantheon%2B_SH0ES.dat",
        # 2. å‚™ç”¨åˆ†æ”¯
        "https://raw.githubusercontent.com/PantheonPlusSH0ES/DataRelease/master/Pantheon+_Data/4_SHOES/Pantheon+_SH0ES.dat",
        # 3. ç°¡åŒ–è·¯å¾‘ (å¦‚æœå‰å…©å€‹å¤±æ•—)
        "https://raw.githubusercontent.com/PantheonPlusSH0ES/DataRelease/main/Pantheon+_Data/4_SHOES/Pantheon+_SH0ES.dat"
    ]
    
    data = None
    for url in urls:
        try:
            headers = {'User-Agent': 'Mozilla/5.0'}
            r = requests.get(url, headers=headers, timeout=15)
            if r.status_code == 200:
                data = pd.read_csv(io.StringIO(r.text), sep=r'\s+')
                print(f"    -> [æˆåŠŸ] å·²é€£ç·šè‡³: {url[:60]}...")
                break
        except Exception as e:
            continue
            
    if data is None:
        print("\n[âŒ] è‡´å‘½éŒ¯èª¤: ç„¡æ³•é€£æ¥ä»»ä½•çœŸå¯¦æ•¸æ“šæºï¼")
        print("    è«‹ç¢ºèªç¶²è·¯ç’°å¢ƒæ˜¯å¦èƒ½å­˜å– raw.githubusercontent.comã€‚")
        print("    ç‚ºäº†ä¿è­‰ç§‘å­¸åš´è¬¹æ€§ï¼Œæœ¬ç¨‹å¼å·²çµ‚æ­¢ï¼Œæ‹’çµ•ä½¿ç”¨æ¨¡æ“¬æ•¸æ“šã€‚")
        sys.exit() # çµ‚æ­¢ç¨‹å¼ï¼Œä¸é€²è¡Œæ¨¡æ“¬

    # æ¸…æ´—æ•¸æ“š
    mask = (data['zHD'] > 0.01) & (data['IS_DIST_CAND'] > 0)
    return data['zHD'][mask].values, data['m_b_corr'][mask].values, data['m_b_corr_err_DIAG'][mask].values

# --- 2. ç‰©ç†è¨ˆç®—æ ¸å¿ƒ ---

def theory_distance_modulus(z, h0, om, alpha=0, beta=0, model='lcdm'):
    c = 299792.458
    dz = 0.01
    z_max = np.max(z)
    z_integ = np.arange(0, z_max + dz, dz)
    Ez_sq = om * (1 + z_integ)**3 + (1 - om)
    
    if model == 'lcdm':
        h_vals = h0 * np.sqrt(Ez_sq)
    else:
        chi_vals = np.log(1 + z_integ)
        correction = 1.0 + beta * (1.0 / np.cosh(alpha * chi_vals))
        h_vals = h0 * np.sqrt(Ez_sq) * correction
        
    inv_h = 1.0 / h_vals
    dc = np.cumsum(inv_h) * dz * c
    dc_interp = np.interp(z, z_integ, dc)
    dl = (1 + z) * dc_interp
    return 5.0 * np.log10(np.maximum(dl, 1e-10)) + 25.0

def log_likelihood(theta, z, mu, err, model_type):
    if model_type == 'lcdm':
        h0, om = theta
        alpha, beta = 0, 0
    else:
        h0, om, alpha, beta = theta
        
    if not (60 < h0 < 85 and 0.1 < om < 0.5): return -np.inf
    if model_type == 'hrs' and not (0 < alpha < 5.0 and -0.5 < beta < 0.5): return -np.inf
    
    # å¼·åˆ¶æ³¨å…¥ Planck 2018 è§€æ¸¬å£“åŠ›
    prior_om = -0.5 * ((om - 0.315) / 0.007)**2
    
    mu_model = theory_distance_modulus(z, h0, om, alpha, beta, model_type)
    diff = mu - mu_model
    offset = np.mean(diff)
    chisq = np.sum(((diff - offset) / err)**2)
    return -0.5 * chisq + prior_om

# --- 3. åŸ·è¡Œåˆ†æ ---

if __name__ == "__main__":
    z_real, mu_real, err_real = get_real_pantheon_data()
    
    # ç‚ºäº†çµ±è¨ˆçœŸå¯¦æ€§ï¼Œéš¨æ©ŸæŠ½æ¨£ 500 å€‹çœŸå¯¦é»ä½
    np.random.seed(42)
    idx = np.random.choice(len(z_real), 500, replace=False)
    z, mu, err = z_real[idx], mu_real[idx], err_real[idx]

    print(f"\n[*] æ­£åœ¨å° {len(z)} å€‹ã€ŒçœŸå¯¦ã€è§€æ¸¬é»åŸ·è¡Œæ¨¡å‹å°æŠ—æ¸¬è©¦...")
    
    nwalkers, steps = 32, 600
    sampler_l = emcee.EnsembleSampler(nwalkers, 2, log_likelihood, args=(z, mu, err, 'lcdm'))
    sampler_l.run_mcmc([73.0, 0.31] + 1e-3*np.random.randn(nwalkers, 2), steps, progress=True)

    sampler_h = emcee.EnsembleSampler(nwalkers, 4, log_likelihood, args=(z, mu, err, 'hrs'))
    sampler_h.run_mcmc([73.0, 0.31, 1.5, 0.05] + 1e-3*np.random.randn(nwalkers, 4), steps, progress=True)

    def get_stats(sampler, k):
        lp = sampler.get_log_prob(discard=100, flat=True)
        best_idx = np.argmax(lp)
        return 2*k - 2*lp[best_idx], sampler.get_chain(discard=100, flat=True)[best_idx]

    aic_l, theta_l = get_stats(sampler_l, 2)
    aic_h, theta_h = get_stats(sampler_h, 4)

    print("\n" + "="*50)
    print("      HRS v6.2.4 çœŸå¯¦æ•¸æ“šæ±ºæˆ°çµæœ")
    print("="*50)
    print(f" Delta AIC : {aic_l - aic_h:.4f}")
    print(f" HRS H0    : {theta_h[0]:.3f} km/s/Mpc")
    print(f" HRS Beta  : {theta_h[3]:.4f}")
    print(f" çµè«–      : {'[å‹] HRS æˆåŠŸè§£é‡‹çœŸå¯¦å¼µåŠ›' if aic_l - aic_h > 2 else '[æ•—] çœŸå¯¦æ•¸æ“šä¸æ”¯æŒ HRS ä¿®æ­£'}")
    print("="*50)

    # ç¹ªåœ–
    labels = [r"$H_0$", r"$\Omega_m$", r"$\alpha$", r"$\beta$"]
    fig = corner.corner(sampler_h.get_chain(discard=100, flat=True), labels=labels, truths=theta_h)
    plt.savefig("hrs_v6_2_4_real_data.png")
    print("[ğŸ‰] çœŸå¯¦æ•¸æ“š Corner Plot å·²å„²å­˜ã€‚")
    
