import subprocess
import sys

# --- è‡ªå‹•ç’°å¢ƒæª¢æŸ¥æ©Ÿåˆ¶ ---
def setup_environment():
    required = {"numpy", "pandas", "matplotlib", "scipy", "requests", "emcee", "corner"}
    try:
        import pkg_resources
        installed = {pkg.key for pkg in pkg_resources.working_set}
        missing = required - installed
        if missing:
            print(f"[*] åµæ¸¬åˆ°ç¼ºå¤±çµ„ä»¶: {missing}ï¼Œæ­£åœ¨è‡ªå‹•å®‰è£...")
            subprocess.check_call([sys.executable, "-m", "pip", "install", *missing])
    except Exception:
        # é‡å° Colab ç’°å¢ƒçš„ç›¸å®¹è™•ç†
        pass

setup_environment()

# --- æ­£å¼å°å…¥ ---

import numpy as np
import pandas as pd
import emcee
import matplotlib.pyplot as plt
import corner
import urllib.request
import io
import ssl
import sys

# --- 1. ä½¿ç”¨å¼·åŒ–çš„ urllib å¼•æ“ç²å–çœŸå¯¦æ•¸æ“š ---

def get_real_data_robust():
    print("[*] æ­£åœ¨é€é SSL éš§é“å­˜å– Pantheon+ çœŸå¯¦æ•¸æ“šåº«...")
    
    # å®˜æ–¹æ•¸æ“šçš„åŸå§‹ä½å€
    url = "https://raw.githubusercontent.com/PantheonPlusSH0ES/DataRelease/main/Pantheon+_Data/4_SHOES/Pantheon+_SH0ES.dat"
    
    # å¿½ç•¥ SSL æ†‘è­‰æª¢æŸ¥ï¼ˆè§£æ±ºæŸäº›é›²ç«¯ç’°å¢ƒçš„é€£ç·šå•é¡Œï¼‰
    context = ssl._create_unverified_context()
    
    try:
        req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
        with urllib.request.urlopen(req, context=context, timeout=20) as response:
            content = response.read().decode('utf-8')
            data = pd.read_csv(io.StringIO(content), sep=r'\s+')
            print(f"    -> [æˆåŠŸ] å·²å®‰å…¨ç²å– {len(data)} æ¢è§€æ¸¬ç´€éŒ„ã€‚")
            
            # æ¸…æ´—æ•¸æ“šï¼šæ’é™¤ IS_DIST_CAND != 1 èˆ‡ z < 0.01
            mask = (data['zHD'] > 0.01) & (data['IS_DIST_CAND'] > 0)
            return data['zHD'][mask].values, data['m_b_corr'][mask].values, data['m_b_corr_err_DIAG'][mask].values
            
    except Exception as e:
        print(f"\n[!] è‡ªå‹•ä¸‹è¼‰å¤±æ•—: {e}")
        print("-" * 50)
        print("ã€æ‰‹å‹•æ“ä½œæŒ‡ç¤ºã€‘")
        print("1. è«‹æ‰‹å‹•ç€è¦½: https://github.com/PantheonPlusSH0ES/DataRelease/blob/main/Pantheon+_Data/4_SHOES/Pantheon+_SH0ES.dat")
        print("2. é»æ“Š 'Download Raw File' ä¸¦å­˜ç‚º 'pantheon.dat'")
        print("3. å°‡æª”æ¡ˆæ‹–å…¥æ­¤åŸ·è¡Œç’°å¢ƒçš„å·¦å´è³‡æ–™å¤¾ã€‚")
        print("-" * 50)
        
        # å˜—è©¦è®€å–æœ¬åœ°æª”æ¡ˆ
        try:
            data = pd.read_csv('pantheon.dat', sep=r'\s+')
            mask = (data['zHD'] > 0.01) & (data['IS_DIST_CAND'] > 0)
            print("[âœ…] å·²æˆåŠŸè®€å–æœ¬åœ°ä¸Šå‚³çš„çœŸå¯¦æ•¸æ“šã€‚")
            return data['zHD'][mask].values, data['m_b_corr'][mask].values, data['m_b_corr_err_DIAG'][mask].values
        except:
            print("[âŒ] æœ¬åœ°æª”æ¡ˆä¸å­˜åœ¨ï¼Œä¸­æ­¢åŸ·è¡Œä»¥ç¶­æŒç§‘å­¸çœŸå¯¦æ€§ã€‚")
            sys.exit()

# --- 2. ç‰©ç†æ¨¡å‹èˆ‡è¨ˆç®— (ä¿æŒ v6.2.4 çš„åš´è¬¹åº¦) ---

def theory_distance_modulus(z, h0, om, alpha=0, beta=0, model='lcdm'):
    c = 299792.458
    dz = 0.01
    z_max = np.max(z)
    z_integ = np.arange(0, z_max + dz, dz)
    Ez_sq = om * (1 + z_integ)**3 + (1 - om)
    if model == 'lcdm':
        h_vals = h0 * np.sqrt(Ez_sq)
    else:
        chi_vals = np.log(1 + z_integ)
        # HRS å…¨æ¯ä¿®æ­£å…¬å¼
        correction = 1.0 + beta * (1.0 / np.cosh(alpha * chi_vals))
        h_vals = h0 * np.sqrt(Ez_sq) * correction
    inv_h = 1.0 / h_vals
    dc = np.cumsum(inv_h) * dz * c
    dc_interp = np.interp(z, z_integ, dc)
    dl = (1 + z) * dc_interp
    return 5.0 * np.log10(np.maximum(dl, 1e-10)) + 25.0

def log_likelihood(theta, z, mu, err, model_type):
    if model_type == 'lcdm':
        h0, om = theta
        alpha, beta = 0, 0
    else:
        h0, om, alpha, beta = theta
    if not (60 < h0 < 85 and 0.1 < om < 0.5): return -np.inf
    if model_type == 'hrs' and not (0 < alpha < 5.0 and -0.5 < beta < 0.5): return -np.inf
    
    # æ³¨å…¥æ™®æœ—å…‹è§€æ¸¬å£“åŠ› (Omega_m = 0.315)
    prior_om = -0.5 * ((om - 0.315) / 0.007)**2
    
    mu_model = theory_distance_modulus(z, h0, om, alpha, beta, model_type)
    diff = mu - mu_model
    offset = np.mean(diff) 
    chisq = np.sum(((diff - offset) / err)**2)
    return -0.5 * chisq + prior_om

# --- 3. åŸ·è¡Œä¸»ç¨‹åº ---

if __name__ == "__main__":
    z_real, mu_real, err_real = get_real_data_robust()
    
    # éš¨æ©ŸæŠ½å–çœŸå¯¦æ¨£æœ¬
    np.random.seed(42)
    idx = np.random.choice(len(z_real), 500, replace=False)
    z, mu, err = z_real[idx], mu_real[idx], err_real[idx]

    print(f"[*] æ­£åœ¨å° {len(z)} ç­†çœŸå¯¦æ•¸æ“šé€²è¡Œã€Œå“ˆä¼¯å¼µåŠ›ã€å°æŠ—æ¸¬è©¦...")
    
    nwalkers, steps = 32, 600
    # LCDM
    sampler_l = emcee.EnsembleSampler(nwalkers, 2, log_likelihood, args=(z, mu, err, 'lcdm'))
    sampler_l.run_mcmc([73.0, 0.31] + 1e-3*np.random.randn(nwalkers, 2), steps, progress=True)

    # HRS
    sampler_h = emcee.EnsembleSampler(nwalkers, 4, log_likelihood, args=(z, mu, err, 'hrs'))
    sampler_h.run_mcmc([73.0, 0.31, 1.5, 0.05] + 1e-3*np.random.randn(nwalkers, 4), steps, progress=True)

    def get_stats(sampler, k):
        lp = sampler.get_log_prob(discard=100, flat=True)
        best_idx = np.argmax(lp)
        return 2*k - 2*lp[best_idx], sampler.get_chain(discard=100, flat=True)[best_idx]

    aic_l, theta_l = get_stats(sampler_l, 2)
    aic_h, theta_h = get_stats(sampler_h, 4)

    print("\n" + "="*50)
    print(f"      HRS v6.2.5 æ±ºæˆ°å ±å‘Š (çœŸå¯¦æ•¸æ“š)")
    print("="*50)
    print(f" Delta AIC : {aic_l - aic_h:.4f}")
    print(f" HRS H0    : {theta_h[0]:.3f}")
    print(f" HRS Beta  : {theta_h[3]:.4f}")
    print(f" æœ€çµ‚çµè«–  : {'[å‹] ç™¼ç¾å…¨æ¯æ•ˆæ‡‰ç‰¹å¾µ' if aic_l - aic_h > 2 else '[å¹³] æ•¸æ“šåå‘å‚³çµ±æ¨¡å‹'}")
    print("="*50)

    # ç¹ªåœ–
    labels = [r"$H_0$", r"$\Omega_m$", r"$\alpha$", r"$\beta$"]
    fig = corner.corner(sampler_h.get_chain(discard=100, flat=True), labels=labels, truths=theta_h)
    plt.savefig("hrs_v6_2_5_real_final.png")
    print("[ğŸ‰] é©—è­‰åœ–è¡¨å·²å„²å­˜ã€‚")


