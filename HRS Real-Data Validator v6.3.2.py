import subprocess
import sys

# --- è‡ªå‹•ç’°å¢ƒæª¢æŸ¥æ©Ÿåˆ¶ ---
def setup_environment():
    required = {"numpy", "pandas", "matplotlib", "scipy", "requests", "emcee", "corner"}
    try:
        import pkg_resources
        installed = {pkg.key for pkg in pkg_resources.working_set}
        missing = required - installed
        if missing:
            print(f"[*] åµæ¸¬åˆ°ç¼ºå¤±çµ„ä»¶: {missing}ï¼Œæ­£åœ¨è‡ªå‹•å®‰è£...")
            subprocess.check_call([sys.executable, "-m", "pip", "install", *missing])
    except Exception:
        # é‡å° Colab ç’°å¢ƒçš„ç›¸å®¹è™•ç†
        pass

setup_environment()

# --- æ­£å¼å°å…¥ ---

import numpy as np
import pandas as pd
import emcee
import corner
import matplotlib.pyplot as plt
import os

# ==========================================
# 1. å°ˆæ¥­ç´šæ•¸æ“šè¼‰å…¥å™¨ (ä¿®æ­£ Header ä½ç§»å•é¡Œ)
# ==========================================
def load_official_pantheon_plus():
    print("[*] æ­£åœ¨è¼‰å…¥ Pantheon+ å®˜æ–¹æ•¸æ“šåº«...")
    
    dat_file = "Pantheon+SH0ES.dat"
    cov_file = "Pantheon+SH0ES_STAT+SYS.cov"
    
    if not (os.path.exists(dat_file) and os.path.exists(cov_file)):
        print("[âŒ] éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æª”æ¡ˆï¼è«‹ç¢ºä¿æª”æ¡ˆå·²ä¸Šå‚³ä¸”æª”åå®Œå…¨æ­£ç¢ºã€‚")
        return None, None, None

    # 1. è®€å–è§€æ¸¬æ•¸æ“š
    df = pd.read_csv(dat_file, sep=r'\s+')
    
    # 2. è®€å–å”æ–¹å·®çŸ©é™£ (è™•ç† Header)
    print("    -> æ­£åœ¨è®€å–å”æ–¹å·®çŸ©é™£ä¸¦æ’é™¤æ¨™é ­...")
    # ä½¿ç”¨ np.fromfile ä¸¦æ‰‹å‹•è™•ç†ç¬¬ä¸€å€‹å…ƒç´ 
    raw_data = np.fromfile(cov_file, sep=' ')
    
    # æª”æ¡ˆçš„ç¬¬ä¸€å€‹æ•¸å­—é€šå¸¸æ˜¯çŸ©é™£å¤§å° (1701)
    n_header = int(raw_data[0])
    # çœŸæ­£çš„æ•¸æ“šæ˜¯å¾ç´¢å¼• 1 é–‹å§‹
    matrix_data = raw_data[1:]
    
    print(f"    -> åµæ¸¬åˆ°æ¨™é ­ N={n_header}, å‰©é¤˜æ•¸æ“šé‡={len(matrix_data)}")
    
    if len(matrix_data) != n_header * n_header:
        # å¦‚æœé‚„æ˜¯å°ä¸èµ·ä¾†ï¼Œå˜—è©¦å…¨é‡è®€å– (æŸäº›ç‰ˆæœ¬å¯èƒ½æ²’æœ‰æ¨™é ­)
        if len(raw_data) == n_header * n_header:
            print("    [!] åµæ¸¬åˆ°ç„¡æ¨™é ­æ ¼å¼ï¼Œè‡ªå‹•èª¿æ•´...")
            matrix_data = raw_data
        else:
            print(f"[âŒ] çŸ©é™£å¤§å°ä¸åŒ¹é…ï¼šæœŸæœ› {n_header**2}ï¼Œå¯¦éš› {len(matrix_data)}")
            return None, None, None

    cov_matrix = matrix_data.reshape((n_header, n_header))

    # 3. æ•¸æ“šéæ¿¾ (zHD > 0.01 æ˜¯ Pantheon+ å»ºè­°çš„å®‡å®™å­¸åŸºæº–)
    mask = (df['zHD'] > 0.01)
    df_clean = df[mask].reset_index(drop=True)
    z_obs = df_clean['zHD'].values
    mu_obs = df_clean['m_b_corr'].values
    
    # åŒæ­¥åˆ‡å‰²çŸ©é™£
    indices = df.index[mask].values
    cov_matrix_cut = cov_matrix[np.ix_(indices, indices)]
    
    print("    -> æ­£åœ¨è¨ˆç®—åçŸ©é™£ (é€™éœ€è¦ä¸€é» CPU æ•ˆèƒ½)...")
    inv_cov = np.linalg.inv(cov_matrix_cut)
    
    print(f"[âœ…] æ•¸æ“šæˆåŠŸå°é½Šï¼š{len(z_obs)} å€‹é»ä½ã€‚")
    return z_obs, mu_obs, inv_cov

# ==========================================
# 2. ç‰©ç†æ¨¡å‹èˆ‡ Likelihood (ç©©å®šç‰ˆ)
# ==========================================
def theory_distance_modulus(z, h0, om, alpha, beta, model='lcdm'):
    c = 299792.458
    # å¢åŠ ç©åˆ†ç²¾åº¦ä»¥å›æ‡‰ GROK çš„æ‰¹è©•
    z_integ = np.linspace(0, np.max(z)*1.05, 1000)
    Ez = np.sqrt(om * (1 + z_integ)**3 + (1 - om))
    
    if model == 'hrs':
        # æŒ‡æ•¸è¡°æ¸›ä¿®æ­£ï¼šç¢ºä¿é«˜ç´…ç§»å›æ­¸ LCDM
        correction = 1.0 + beta * np.exp(-z_integ / alpha)
        hz = h0 * Ez * correction
    else:
        hz = h0 * Ez
        
    inv_hz = 1.0 / hz
    dc_cum = np.cumsum(inv_hz) * (z_integ[1] - z_integ[0]) * c
    dc_interp = np.interp(z, z_integ, dc_cum)
    dl = (1 + z) * dc_interp
    return 5.0 * np.log10(np.maximum(dl, 1e-10)) + 25.0

def log_likelihood(theta, z, mu, inv_cov, model_type):
    if model_type == 'lcdm':
        h0, om = theta
        alpha, beta = 1.0, 0.0
    else:
        h0, om, alpha, beta = theta
    
    # åš´æ ¼çš„ç‰©ç†å…ˆé©—
    if not (65 < h0 < 80 and 0.2 < om < 0.4): return -np.inf
    if model_type == 'hrs' and not (0.01 < alpha < 3.0 and -0.2 < beta < 1.0): return -np.inf

    mu_model = theory_distance_modulus(z, h0, om, alpha, beta, model_type)
    diff = mu - mu_model
    # çŸ©é™£å¡æ–¹é‹ç®—
    chisq = np.dot(diff, np.dot(inv_cov, diff))
    return -0.5 * chisq

# ==========================================
# 3. åŸ·è¡Œåˆ†æèˆ‡çµ±è¨ˆ
# ==========================================
if __name__ == "__main__":
    z, mu, inv_cov = load_official_pantheon_plus()
    
    if z is not None:
        n_data = len(z)
        nwalkers, steps = 32, 1000
        
        # --- åŸ·è¡Œ LCDM ---
        print("\n[*] æ­£åœ¨åŸ·è¡ŒåŸºæº–æ¨¡å‹ LCDM...")
        sampler_l = emcee.EnsembleSampler(nwalkers, 2, log_likelihood, args=(z, mu, inv_cov, 'lcdm'))
        sampler_l.run_mcmc([73.0, 0.31] + 1e-3*np.random.randn(nwalkers, 2), steps, progress=True)
        
        # --- åŸ·è¡Œ HRS ---
        print("\n[*] æ­£åœ¨åŸ·è¡Œå…¨æ¯ä¿®æ­£æ¨¡å‹ HRS (Evolutionary)...")
        sampler_h = emcee.EnsembleSampler(nwalkers, 4, log_likelihood, args=(z, mu, inv_cov, 'hrs'))
        sampler_h.run_mcmc([73.0, 0.31, 0.5, 0.05] + 1e-3*np.random.randn(nwalkers, 4), steps, progress=True)

        # çµ±è¨ˆåˆ†æ
        def get_metrics(sampler, k):
            lp = sampler.get_log_prob(discard=200, flat=True)
            max_log_like = np.max(lp)
            aic = 2*k - 2*max_log_like
            bic = k * np.log(n_data) - 2*max_log_like
            best_theta = sampler.get_chain(discard=200, flat=True)[np.argmax(lp)]
            return aic, bic, best_theta

        aic_l, bic_l, theta_l = get_metrics(sampler_l, 2)
        aic_h, bic_h, theta_h = get_metrics(sampler_h, 4)

        print("\n" + "="*50)
        print("   HRS v6.3.2 æ•¸æ“šå°é½Šé©—è­‰å ±å‘Š")
        print("="*50)
        print(f" Delta AIC: {aic_l - aic_h:.4f}")
        print(f" Delta BIC: {bic_l - bic_h:.4f}")
        print("-" * 50)
        print(f" HRS æœ€ä½³æ“¬åˆ H0: {theta_h[0]:.3f}")
        print(f" HRS å…¨æ¯å¼·åº¦ Beta: {theta_h[3]:.4f}")
        print("-" * 50)
        
        # ç¹ªåœ–
        labels = [r"$H_0$", r"$\Omega_m$", r"$\alpha$", r"$\beta$"]
        samples = sampler_h.get_chain(discard=200, flat=True)
        fig = corner.corner(samples, labels=labels, truths=theta_h, show_titles=True)
        plt.savefig("hrs_v6_3_2_final.png")
        print("[ğŸ‰] æˆåŠŸï¼è«‹æŸ¥çœ‹çµæœèˆ‡åœ–è¡¨ã€‚")

