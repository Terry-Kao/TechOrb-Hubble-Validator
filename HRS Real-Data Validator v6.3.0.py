import subprocess
import sys

# --- è‡ªå‹•ç’°å¢ƒæª¢æŸ¥æ©Ÿåˆ¶ ---
def setup_environment():
    required = {"numpy", "pandas", "matplotlib", "scipy", "requests", "emcee", "corner"}
    try:
        import pkg_resources
        installed = {pkg.key for pkg in pkg_resources.working_set}
        missing = required - installed
        if missing:
            print(f"[*] åµæ¸¬åˆ°ç¼ºå¤±çµ„ä»¶: {missing}ï¼Œæ­£åœ¨è‡ªå‹•å®‰è£...")
            subprocess.check_call([sys.executable, "-m", "pip", "install", *missing])
    except Exception:
        # é‡å° Colab ç’°å¢ƒçš„ç›¸å®¹è™•ç†
        pass

setup_environment()

# --- æ­£å¼å°å…¥ ---

import numpy as np
import pandas as pd
import emcee
import corner
import matplotlib.pyplot as plt
import requests
import io
import time

# ==========================================
# 1. å°ˆæ¥­ç´šæ•¸æ“šè¼‰å…¥å™¨ (ç›´æ¥å¾ GitHub Raw ç²å–)
# ==========================================
def load_official_pantheon_plus():
    print("[*] æ­£åœ¨å»ºç«‹èˆ‡ Pantheon+ å®˜æ–¹æ•¸æ“šåº«çš„é€£ç·š...")
    
    # å®šç¾© Raw URL (æ³¨æ„ URL ç·¨ç¢¼)
    base_url = "https://raw.githubusercontent.com/PantheonPlusSH0ES/DataRelease/main/Pantheon%2B_Data/4_DISTANCES_AND_COVAR/"
    dat_url = base_url + "Pantheon%2B_SH0ES.dat"
    cov_url = base_url + "Pantheon%2B_SH0ES_STAT%2BSYS.cov"
    
    # 1. ä¸‹è¼‰ä¸¦è§£ææ•¸æ“šè¡¨ (.dat)
    print("    -> æ­£åœ¨ä¸‹è¼‰è§€æ¸¬æ•¸æ“šè¡¨ (Pantheon+SH0ES.dat)...")
    r_dat = requests.get(dat_url)
    if r_dat.status_code != 200: raise Exception("ç„¡æ³•ä¸‹è¼‰æ•¸æ“šè¡¨")
    
    # ä½¿ç”¨ Pandas è®€å– (ç¬¬ä¸€è¡Œæ˜¯æ¨™é¡Œ)
    df = pd.read_csv(io.StringIO(r_dat.text), sep=r'\s+')
    
    # ç¯©é¸æ•¸æ“šï¼šåªä¿ç•™ç”¨æ–¼å®‡å®™å­¸æ“¬åˆçš„æ¨£æœ¬ (zHD > 0.01)
    # æ³¨æ„ï¼šPantheon+ å®˜æ–¹å»ºè­°ä½¿ç”¨ HELIO_Z æˆ– zHDï¼Œé€™è£¡ä½¿ç”¨ zHD
    mask = (df['zHD'] > 0.01)
    df_clean = df[mask].reset_index(drop=True)
    
    z_obs = df_clean['zHD'].values
    mu_obs = df_clean['m_b_corr'].values
    print(f"    -> [æˆåŠŸ] å·²è¼‰å…¥ {len(z_obs)} å€‹æœ‰æ•ˆè§€æ¸¬é»ã€‚")

    # 2. ä¸‹è¼‰ä¸¦è§£æå”æ–¹å·®çŸ©é™£ (.cov)
    print("    -> æ­£åœ¨ä¸‹è¼‰ä¸¦å»ºæ§‹ 1701x1701 å”æ–¹å·®çŸ©é™£ (é€™å¯èƒ½éœ€è¦ä¸€é»æ™‚é–“)...")
    r_cov = requests.get(cov_url)
    if r_cov.status_code != 200: raise Exception("ç„¡æ³•ä¸‹è¼‰å”æ–¹å·®çŸ©é™£")
    
    # è®€å–ç´”æ–‡æœ¬çŸ©é™£æ•¸æ“š
    raw_cov_data = np.fromstring(r_cov.text, sep=' ')
    
    # æª¢æŸ¥çŸ©é™£å¤§å°æ˜¯å¦æ­£ç¢º (æ‡‰è©²æ˜¯ N_total * N_total)
    n_total = int(np.sqrt(len(raw_cov_data)))
    print(f"    -> åŸå§‹çŸ©é™£ç¶­åº¦: {n_total}x{n_total}")
    
    cov_matrix = raw_cov_data.reshape((n_total, n_total))
    
    # é—œéµæ­¥é©Ÿï¼šæ ¹æ“šä¸Šé¢çš„ mask åŒæ­¥åˆ‡å‰²çŸ©é™£
    # æˆ‘å€‘å¿…é ˆåªä¿ç•™èˆ‡ z_obs å°æ‡‰çš„è¡Œèˆ‡åˆ—
    indices = df.index[mask].values
    cov_matrix_cut = cov_matrix[np.ix_(indices, indices)]
    
    # é å…ˆè¨ˆç®—åçŸ©é™£ (Inverse Covariance Matrix) ä»¥åŠ é€Ÿ MCMC
    # ä½¿ç”¨ Cholesky åˆ†è§£æˆ–å½é€†çŸ©é™£ä¾†å¢åŠ æ•¸å€¼ç©©å®šæ€§
    print("    -> æ­£åœ¨è¨ˆç®—åçŸ©é™£ (Inverting Covariance Matrix)...")
    try:
        inv_cov = np.linalg.inv(cov_matrix_cut)
    except np.linalg.LinAlgError:
        print("    [!] è­¦å‘Šï¼šçŸ©é™£å¥‡ç•°ï¼Œæ”¹ç”¨å½é€†çŸ©é™£ (Pseudo-inverse)")
        inv_cov = np.linalg.pinv(cov_matrix_cut)
        
    print(f"    -> [æˆåŠŸ] æ•¸æ“šæº–å‚™å®Œæˆã€‚")
    return z_obs, mu_obs, inv_cov

# ==========================================
# 2. ç‰©ç†æ¨¡å‹æ ¸å¿ƒ (Evolutionary HRS)
# ==========================================
def theory_distance_modulus(z, h0, om, alpha=0, beta=0, model='lcdm'):
    # ç‰©ç†å¸¸æ•¸
    c = 299792.458 # å…‰é€Ÿ km/s
    
    # ç©åˆ†ç¶²æ ¼
    z_integ = np.linspace(0, np.max(z)*1.1, 1000)
    
    # æ¨™æº– LCDM è†¨è„¹ç‡ E(z) = H(z)/H0
    # å¿½ç•¥è¼»å°„é … (åœ¨ z < 2.5 å½±éŸ¿æ¥µå°)ï¼Œä½†ä¿ç•™æ›²ç‡é …ç‚º 0 (å¹³å¦å®‡å®™)
    Ez = np.sqrt(om * (1 + z_integ)**3 + (1 - om))
    
    if model == 'hrs':
        # --- GROK ä¿®æ­£å›æ‡‰ ---
        # ä½¿ç”¨æŒ‡æ•¸è¡°æ¸›å½¢å¼ï¼šCorrection = 1 + beta * exp(-z/alpha)
        # ç•¶ z >> alpha æ™‚ï¼Œä¿®æ­£é …æ¶ˆå¤±ï¼Œå›æ­¸ LCDM (æ»¿è¶³ CMB/BBN é™åˆ¶)
        # ç•¶ z -> 0 æ™‚ï¼ŒH(z) -> H0 * (1 + beta)ï¼Œé€™è§£é‡‹äº†ç‚ºä»€éº¼æœ¬åœ°æ¸¬é‡å€¼è¼ƒé«˜
        correction = 1.0 + beta * np.exp(-z_integ / alpha)
        
        # ä¿®æ­£å¾Œçš„å“ˆä¼¯åƒæ•¸
        hz = h0 * Ez * correction
    else:
        hz = h0 * Ez
        
    # è¨ˆç®—å…±å‹•è·é›¢ Dc
    inv_hz = 1.0 / hz
    dc = np.trapz(inv_hz, z_integ) # ç¸½ç©åˆ†
    
    # å› ç‚ºæˆ‘å€‘è¦å°æ¯å€‹ z è¨ˆç®—ç©åˆ†ï¼Œé€™è£¡ä½¿ç”¨ç´¯ç©ç©åˆ†æ’å€¼åŠ é€Ÿ
    dc_cum = pd.Series(inv_hz).rolling(2).mean().fillna(0).cumsum().values * (z_integ[1] - z_integ[0]) * c
    dc_interp = np.interp(z, z_integ, dc_cum)
    
    # å…‰åº¦è·é›¢ Dl = (1+z) * Dc
    dl = (1 + z) * dc_interp
    
    # è·é›¢æ¨¡æ•¸ mu = 5 log10(Dl) + 25
    return 5.0 * np.log10(np.maximum(dl, 1e-10)) + 25.0

# ==========================================
# 3. çµ±è¨ˆæ¨æ–· (Likelihood & MCMC)
# ==========================================
def log_likelihood(theta, z, mu, inv_cov, model_type):
    if model_type == 'lcdm':
        h0, om = theta
        alpha, beta = 1.0, 0.0 # ä½”ä½ç¬¦
    else:
        h0, om, alpha, beta = theta
        
    # --- åƒæ•¸é‚Šç•Œæª¢æŸ¥ (Priors) ---
    if not (60 < h0 < 85): return -np.inf
    if not (0.1 < om < 0.5): return -np.inf
    
    if model_type == 'hrs':
        # Alpha (è¡°æ¸›å°ºåº¦): é™åˆ¶åœ¨ 0.01 ~ 5.0 (å°æ‡‰ z çš„ç¯„åœ)
        if not (0.01 < alpha < 5.0): return -np.inf 
        # Beta (å¼·åº¦): é™åˆ¶åœ¨ -0.5 ~ 1.5
        if not (-0.5 < beta < 1.5): return -np.inf

    # è¨ˆç®—ç†è«–å€¼
    mu_model = theory_distance_modulus(z, h0, om, alpha, beta, model_type)
    
    # è¨ˆç®—æ®˜å·®å‘é‡
    diff = mu - mu_model
    
    # --- çŸ©é™£ç´šå¡æ–¹é‹ç®— (Chi-Square) ---
    # Chi2 = (Diff)^T * Cov^(-1) * (Diff)
    # é€™ä¸€æ­¥è‡ªå‹•è™•ç†äº†æ‰€æœ‰ç›¸é—œæ€§èª¤å·®èˆ‡çµ•å°æ˜Ÿç­‰ M_B çš„æ ¡æº–æ¬Šé‡
    chisq = np.dot(diff, np.dot(inv_cov, diff))
    
    return -0.5 * chisq

# ==========================================
# 4. ä¸»åŸ·è¡Œç¨‹åº
# ==========================================
if __name__ == "__main__":
    print("==================================================")
    print("   HRS v6.3.0 Real-Data Validator (Professional)  ")
    print("==================================================")
    
    # 1. è¼‰å…¥æ•¸æ“š
    try:
        z, mu, inv_cov = load_official_pantheon_plus()
    except Exception as e:
        print(f"[ERROR] {e}")
        exit()

    print(f"\n[*] å•Ÿå‹• MCMC æ¡æ¨£ (N={len(z)}, Full Covariance)...")
    print("    æ³¨æ„ï¼šç”±æ–¼çŸ©é™£é‹ç®—é‡å¤§ï¼Œæ­¤æ­¥é©Ÿå¯èƒ½éœ€è¦ 5-10 åˆ†é˜ï¼Œè«‹è€å¿ƒç­‰å¾…ã€‚")
    
    nwalkers = 32
    steps = 800 # æ­¥æ•¸é©ä¸­ï¼Œç¢ºä¿æ”¶æ–‚å³å¯
    ndim_l = 2
    ndim_h = 4
    
    # --- åŸ·è¡Œ LCDM ---
    print("\n[1/2] æ­£åœ¨åŸ·è¡Œæ¨™æº–æ¨¡å‹ (LCDM)...")
    pos_l = [73.0, 0.315] + 1e-3 * np.random.randn(nwalkers, ndim_l)
    sampler_l = emcee.EnsembleSampler(nwalkers, ndim_l, log_likelihood, args=(z, mu, inv_cov, 'lcdm'))
    sampler_l.run_mcmc(pos_l, steps, progress=True)
    
    # --- åŸ·è¡Œ HRS (Evolutionary) ---
    print("\n[2/2] æ­£åœ¨åŸ·è¡Œå…¨æ¯ä¿®æ­£æ¨¡å‹ (HRS v6.3)...")
    # åˆå§‹çŒœæ¸¬: H0=73, Om=0.315, Alpha=0.5 (åœ¨ z=0.5 è¡°æ¸›), Beta=0.1 (10% ä¿®æ­£)
    pos_h = [73.0, 0.315, 0.5, 0.1] + 1e-3 * np.random.randn(nwalkers, ndim_h)
    sampler_h = emcee.EnsembleSampler(nwalkers, ndim_h, log_likelihood, args=(z, mu, inv_cov, 'hrs'))
    sampler_h.run_mcmc(pos_h, steps, progress=True)

    # --- åˆ†æçµæœ ---
    def get_info_criteria(sampler, k, n_data):
        # ç²å–æœ€ä½³ Log Likelihood
        log_prob = sampler.get_log_prob(discard=200, flat=True)
        max_log_like = np.max(log_prob)
        
        # AIC = 2k - 2ln(L)
        aic = 2*k - 2*max_log_like
        # BIC = k*ln(n) - 2ln(L) (æ‡²ç½°æ›´é‡)
        bic = k*np.log(n_data) - 2*max_log_like
        
        # ç²å–æœ€ä½³åƒæ•¸
        best_idx = np.argmax(log_prob)
        theta = sampler.get_chain(discard=200, flat=True)[best_idx]
        return aic, bic, theta

    aic_l, bic_l, theta_l = get_info_criteria(sampler_l, 2, len(z))
    aic_h, bic_h, theta_h = get_info_criteria(sampler_h, 4, len(z))

    print("\n" + "="*60)
    print("      HRS v6.3.0 æœ€çµ‚æ±ºæˆ°å ±å‘Š (Pantheon+ Full)")
    print("="*60)
    print(f" æ¨¡å‹æ¯”è¼ƒ       | LCDM (æ¨™æº–) | HRS (å…¨æ¯)")
    print(f" ---------------|-------------|-------------")
    print(f" åƒæ•¸æ•¸é‡ (k)   | 2           | 4")
    print(f" AIC (è¶Šä½è¶Šå¥½) | {aic_l:.2f}    | {aic_h:.2f}")
    print(f" BIC (è¶Šä½è¶Šå¥½) | {bic_l:.2f}    | {bic_h:.2f}")
    print("-" * 60)
    print(f" Delta AIC      : {aic_l - aic_h:.4f} ({'æ”¯æŒ HRS' if aic_l > aic_h else 'æ”¯æŒ LCDM'})")
    print(f" Delta BIC      : {bic_l - bic_h:.4f} ({'æ”¯æŒ HRS' if bic_l > bic_h else 'æ”¯æŒ LCDM'})")
    print("-" * 60)
    print(f" HRS æœ€ä½³åƒæ•¸:")
    print(f" H0    : {theta_h[0]:.3f} km/s/Mpc")
    print(f" Omega_m : {theta_h[1]:.3f}")
    print(f" Alpha : {theta_h[2]:.4f} (è¡°æ¸›ç´…ç§»å°ºåº¦ z_c)")
    print(f" Beta  : {theta_h[3]:.4f} (æœ¬åœ°ä¿®æ­£å¼·åº¦)")
    print("="*60)

    # ç¹ªåœ–
    labels = [r"$H_0$", r"$\Omega_m$", r"$\alpha$", r"$\beta$"]
    fig = corner.corner(sampler_h.get_chain(discard=200, flat=True), labels=labels, truths=theta_h, 
                        show_titles=True, title_fmt=".3f")
    plt.savefig("hrs_v6_3_0_full_matrix.png")
    print("[ğŸ‰] é©—è­‰å®Œæˆï¼Œåœ–è¡¨å·²å„²å­˜ç‚º 'hrs_v6_3_0_full_matrix.png'")
